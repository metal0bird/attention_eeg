{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOCUS_SOURCE_DIR = \"dataset_2/focus/\"\n",
    "UNFOCUS_SOURCE_DIR = \"dataset_2/unfocus/\"\n",
    "#DROWSY_SOURCE_DIR = \"dataset_2/drowsy/\"\n",
    "\n",
    "TRAINING_DIR = 'images_2/training/'\n",
    "VALIDATION_DIR = 'images_2/validation/'\n",
    "\n",
    "TRAINING_FOCUS_DIR = os.path.join(TRAINING_DIR, \"focus/\")\n",
    "VALIDATION_FOCUS_DIR = os.path.join(VALIDATION_DIR, \"focus/\")\n",
    "\n",
    "TRAINING_UNFOCUS_DIR = os.path.join(TRAINING_DIR, \"unfocus/\")\n",
    "VALIDATION_UNFOCUS_DIR = os.path.join(VALIDATION_DIR, \"unfocus/\")\n",
    "\n",
    "#TRAINING_DROWSY_DIR = os.path.join(TRAINING_DIR, \"drowsy/\")\n",
    "#VALIDATION_DROWSY_DIR = os.path.join(VALIDATION_DIR, \"drowsy/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original focus's directory has 12870 images\n",
      "Original unfocus's directory has 12870 images\n",
      "There are 9009 images of focus for training\n",
      "There are 9009 images of unfocus for training\n",
      "There are 3861 images of focus for validation\n",
      "There are 3861 images of unfocus for validation\n"
     ]
    }
   ],
   "source": [
    "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
    "print(f\"Original focus's directory has {len(os.listdir(FOCUS_SOURCE_DIR))} images\")\n",
    "print(f\"Original unfocus's directory has {len(os.listdir(UNFOCUS_SOURCE_DIR))} images\")\n",
    "#print(f\"Original drowsy's directory has {len(os.listdir(DROWSY_SOURCE_DIR))} images\\n\")\n",
    "\n",
    "# Training and validation splits\n",
    "print(f\"There are {len(os.listdir(TRAINING_FOCUS_DIR))} images of focus for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_UNFOCUS_DIR))} images of unfocus for training\")\n",
    "#print(f\"There are {len(os.listdir(TRAINING_DROWSY_DIR))} images of drowsy for training\\n\")\n",
    "\n",
    "print(f\"There are {len(os.listdir(VALIDATION_FOCUS_DIR))} images of focus for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_UNFOCUS_DIR))} images of unfocus for validation\")\n",
    "#print(f\"There are {len(os.listdir(VALIDATION_DROWSY_DIR))} images of drowsy for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "\n",
    "  train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='binary', #categorical\n",
    "                                                      target_size=(224, 224)\n",
    "                                                      )\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=32,\n",
    "                                                                class_mode='binary', # categorical\n",
    "                                                                target_size=(224, 224)\n",
    "                                                                )\n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18018 images belonging to 2 classes.\n",
      "Found 7722 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 128s 2us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Optional fully connected layer\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # Output layer for binary classification\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 66/564 [==>...........................] - ETA: 1:55 - loss: 0.6284 - accuracy: 0.6610"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
