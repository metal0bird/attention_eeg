{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/aman/Github bs/datasets/EEG Data/eeg_record7.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record6.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record4.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record5.mat', '/Users/aman/Github bs/datasets/EEG Data/.DS_Store', '/Users/aman/Github bs/datasets/EEG Data/eeg_record1.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record2.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record3.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record16.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record17.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record15.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record29.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record28.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record14.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record10.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record11.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record13.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record12.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record23.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record22.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record20.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record34.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record21.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record19.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record25.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record31.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record30.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record24.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record18.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record32.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record26.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record27.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record33.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record8.mat', '/Users/aman/Github bs/datasets/EEG Data/eeg_record9.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record7.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record6.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record4.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record5.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record1.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record2.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record3.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record16.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record17.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record15.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record29.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record28.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record14.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record10.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record11.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record13.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record12.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record23.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record22.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record20.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record34.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record21.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record19.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record25.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record31.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record30.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record24.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record18.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record32.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record26.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record27.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record33.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record8.mat', '/Users/aman/Github bs/datasets/EEG Data/EEG Data/eeg_record9.mat']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftshift\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "file_names=[]\n",
    "for dirname, _, filenames in os.walk('/Users/aman/Github bs/datasets/EEG Data/'):\n",
    "    for filename in filenames:\n",
    "        file_names.append(os.path.join(dirname, filename))\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        \n",
    "print(file_names)\n",
    "# each trial is about 54 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build 5 order high pass filter\n",
    "from scipy.signal import butter, lfilter, freqz   \n",
    "# ----- ----- ----- -----    \n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    x = signal.filtfilt(b, a, data)\n",
    "    y = signal.filtfilt(b, a, x)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker=128*60*10\n",
    "#delete file #28 and 14 because it doesnot have enough data\n",
    "useful_file_index = [3,4,5,6,7,10,11,12,13,17,18,19,20,21,24,25,26,27,31,32,33,34]\n",
    "#useful_file_index = np.arange(1,35)\n",
    "useful_channels=[4,5,8,9,10,11,16]\n",
    "useful_channels_names=['F7','F3','P7','O1','O2','P8','AF4']\n",
    "chan_num=7\n",
    "trail_names=[]\n",
    "data_focus={}\n",
    "data_unfocus={}\n",
    "data_drowsy={}\n",
    "focus={}\n",
    "unfocus={}\n",
    "drowsy={}\n",
    "#for i in useful_file_index:\n",
    "i=1\n",
    "for index,filename in enumerate(filenames):\n",
    "    if int(filename.split('d')[1].split('.')[0]) in useful_file_index:\n",
    "        mat = scipy.io.loadmat(file_names[index])\n",
    "        trail_names.append(filename.split('.')[0])\n",
    "        data_focus[trail_names[-1]]=mat['o']['data'][0,0][0:marker,useful_channels].copy()\n",
    "        data_unfocus[trail_names[-1]]=mat['o']['data'][0,0][marker:2*marker,useful_channels].copy()\n",
    "        data_drowsy[trail_names[-1]]=mat['o']['data'][0,0][2*marker:3*marker,useful_channels].copy()\n",
    "        focus[trail_names[-1]]=mat['o']['data'][0,0][0:marker,useful_channels].copy()\n",
    "        unfocus[trail_names[-1]]=mat['o']['data'][0,0][marker:2*marker,useful_channels].copy()\n",
    "        drowsy[trail_names[-1]]=mat['o']['data'][0,0][2*marker:3*marker,useful_channels].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76800, 7)\n"
     ]
    }
   ],
   "source": [
    "type(data_focus['eeg_record3'])\n",
    "print(data_focus['eeg_record3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eeg_record7', 'eeg_record6', 'eeg_record4', 'eeg_record5', 'eeg_record3', 'eeg_record17', 'eeg_record10', 'eeg_record11', 'eeg_record13', 'eeg_record12', 'eeg_record20', 'eeg_record34', 'eeg_record21', 'eeg_record19', 'eeg_record25', 'eeg_record31', 'eeg_record24', 'eeg_record18', 'eeg_record32', 'eeg_record26', 'eeg_record27', 'eeg_record33']\n"
     ]
    }
   ],
   "source": [
    "print(trail_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High Pass 0.16HZ\n",
    "row, col = data_focus['eeg_record3'].shape\n",
    "for name in trail_names:\n",
    "    for i in range(col):\n",
    "        data_focus[name][:,i]=butter_highpass_filter(data_focus[name][:,i], 0.16, 128, 5)\n",
    "        data_unfocus[name][:,i]=butter_highpass_filter(data_unfocus[name][:,i], 0.16, 128, 5)\n",
    "        data_drowsy[name][:,i]=butter_highpass_filter(data_drowsy[name][:,i], 0.16, 128, 5)\n",
    "        #print(name,data_drowsy[name][:,i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76800, 7)\n"
     ]
    }
   ],
   "source": [
    "type(data_focus['eeg_record3'])\n",
    "print(data_focus['eeg_record3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F7_0.5',\n",
       " 'F7_1.0',\n",
       " 'F7_1.5',\n",
       " 'F7_2.0',\n",
       " 'F7_2.5',\n",
       " 'F7_3.0',\n",
       " 'F7_3.5',\n",
       " 'F7_4.0',\n",
       " 'F7_4.5',\n",
       " 'F7_5.0',\n",
       " 'F7_5.5',\n",
       " 'F7_6.0',\n",
       " 'F7_6.5',\n",
       " 'F7_7.0',\n",
       " 'F7_7.5',\n",
       " 'F7_8.0',\n",
       " 'F7_8.5',\n",
       " 'F7_9.0',\n",
       " 'F7_9.5',\n",
       " 'F7_10.0',\n",
       " 'F7_10.5',\n",
       " 'F7_11.0',\n",
       " 'F7_11.5',\n",
       " 'F7_12.0',\n",
       " 'F7_12.5',\n",
       " 'F7_13.0',\n",
       " 'F7_13.5',\n",
       " 'F7_14.0',\n",
       " 'F7_14.5',\n",
       " 'F7_15.0',\n",
       " 'F7_15.5',\n",
       " 'F7_16.0',\n",
       " 'F7_16.5',\n",
       " 'F7_17.0',\n",
       " 'F7_17.5',\n",
       " 'F7_18.0',\n",
       " 'F3_0.5',\n",
       " 'F3_1.0',\n",
       " 'F3_1.5',\n",
       " 'F3_2.0',\n",
       " 'F3_2.5',\n",
       " 'F3_3.0',\n",
       " 'F3_3.5',\n",
       " 'F3_4.0',\n",
       " 'F3_4.5',\n",
       " 'F3_5.0',\n",
       " 'F3_5.5',\n",
       " 'F3_6.0',\n",
       " 'F3_6.5',\n",
       " 'F3_7.0',\n",
       " 'F3_7.5',\n",
       " 'F3_8.0',\n",
       " 'F3_8.5',\n",
       " 'F3_9.0',\n",
       " 'F3_9.5',\n",
       " 'F3_10.0',\n",
       " 'F3_10.5',\n",
       " 'F3_11.0',\n",
       " 'F3_11.5',\n",
       " 'F3_12.0',\n",
       " 'F3_12.5',\n",
       " 'F3_13.0',\n",
       " 'F3_13.5',\n",
       " 'F3_14.0',\n",
       " 'F3_14.5',\n",
       " 'F3_15.0',\n",
       " 'F3_15.5',\n",
       " 'F3_16.0',\n",
       " 'F3_16.5',\n",
       " 'F3_17.0',\n",
       " 'F3_17.5',\n",
       " 'F3_18.0',\n",
       " 'P7_0.5',\n",
       " 'P7_1.0',\n",
       " 'P7_1.5',\n",
       " 'P7_2.0',\n",
       " 'P7_2.5',\n",
       " 'P7_3.0',\n",
       " 'P7_3.5',\n",
       " 'P7_4.0',\n",
       " 'P7_4.5',\n",
       " 'P7_5.0',\n",
       " 'P7_5.5',\n",
       " 'P7_6.0',\n",
       " 'P7_6.5',\n",
       " 'P7_7.0',\n",
       " 'P7_7.5',\n",
       " 'P7_8.0',\n",
       " 'P7_8.5',\n",
       " 'P7_9.0',\n",
       " 'P7_9.5',\n",
       " 'P7_10.0',\n",
       " 'P7_10.5',\n",
       " 'P7_11.0',\n",
       " 'P7_11.5',\n",
       " 'P7_12.0',\n",
       " 'P7_12.5',\n",
       " 'P7_13.0',\n",
       " 'P7_13.5',\n",
       " 'P7_14.0',\n",
       " 'P7_14.5',\n",
       " 'P7_15.0',\n",
       " 'P7_15.5',\n",
       " 'P7_16.0',\n",
       " 'P7_16.5',\n",
       " 'P7_17.0',\n",
       " 'P7_17.5',\n",
       " 'P7_18.0',\n",
       " 'O1_0.5',\n",
       " 'O1_1.0',\n",
       " 'O1_1.5',\n",
       " 'O1_2.0',\n",
       " 'O1_2.5',\n",
       " 'O1_3.0',\n",
       " 'O1_3.5',\n",
       " 'O1_4.0',\n",
       " 'O1_4.5',\n",
       " 'O1_5.0',\n",
       " 'O1_5.5',\n",
       " 'O1_6.0',\n",
       " 'O1_6.5',\n",
       " 'O1_7.0',\n",
       " 'O1_7.5',\n",
       " 'O1_8.0',\n",
       " 'O1_8.5',\n",
       " 'O1_9.0',\n",
       " 'O1_9.5',\n",
       " 'O1_10.0',\n",
       " 'O1_10.5',\n",
       " 'O1_11.0',\n",
       " 'O1_11.5',\n",
       " 'O1_12.0',\n",
       " 'O1_12.5',\n",
       " 'O1_13.0',\n",
       " 'O1_13.5',\n",
       " 'O1_14.0',\n",
       " 'O1_14.5',\n",
       " 'O1_15.0',\n",
       " 'O1_15.5',\n",
       " 'O1_16.0',\n",
       " 'O1_16.5',\n",
       " 'O1_17.0',\n",
       " 'O1_17.5',\n",
       " 'O1_18.0',\n",
       " 'O2_0.5',\n",
       " 'O2_1.0',\n",
       " 'O2_1.5',\n",
       " 'O2_2.0',\n",
       " 'O2_2.5',\n",
       " 'O2_3.0',\n",
       " 'O2_3.5',\n",
       " 'O2_4.0',\n",
       " 'O2_4.5',\n",
       " 'O2_5.0',\n",
       " 'O2_5.5',\n",
       " 'O2_6.0',\n",
       " 'O2_6.5',\n",
       " 'O2_7.0',\n",
       " 'O2_7.5',\n",
       " 'O2_8.0',\n",
       " 'O2_8.5',\n",
       " 'O2_9.0',\n",
       " 'O2_9.5',\n",
       " 'O2_10.0',\n",
       " 'O2_10.5',\n",
       " 'O2_11.0',\n",
       " 'O2_11.5',\n",
       " 'O2_12.0',\n",
       " 'O2_12.5',\n",
       " 'O2_13.0',\n",
       " 'O2_13.5',\n",
       " 'O2_14.0',\n",
       " 'O2_14.5',\n",
       " 'O2_15.0',\n",
       " 'O2_15.5',\n",
       " 'O2_16.0',\n",
       " 'O2_16.5',\n",
       " 'O2_17.0',\n",
       " 'O2_17.5',\n",
       " 'O2_18.0',\n",
       " 'P8_0.5',\n",
       " 'P8_1.0',\n",
       " 'P8_1.5',\n",
       " 'P8_2.0',\n",
       " 'P8_2.5',\n",
       " 'P8_3.0',\n",
       " 'P8_3.5',\n",
       " 'P8_4.0',\n",
       " 'P8_4.5',\n",
       " 'P8_5.0',\n",
       " 'P8_5.5',\n",
       " 'P8_6.0',\n",
       " 'P8_6.5',\n",
       " 'P8_7.0',\n",
       " 'P8_7.5',\n",
       " 'P8_8.0',\n",
       " 'P8_8.5',\n",
       " 'P8_9.0',\n",
       " 'P8_9.5',\n",
       " 'P8_10.0',\n",
       " 'P8_10.5',\n",
       " 'P8_11.0',\n",
       " 'P8_11.5',\n",
       " 'P8_12.0',\n",
       " 'P8_12.5',\n",
       " 'P8_13.0',\n",
       " 'P8_13.5',\n",
       " 'P8_14.0',\n",
       " 'P8_14.5',\n",
       " 'P8_15.0',\n",
       " 'P8_15.5',\n",
       " 'P8_16.0',\n",
       " 'P8_16.5',\n",
       " 'P8_17.0',\n",
       " 'P8_17.5',\n",
       " 'P8_18.0',\n",
       " 'AF4_0.5',\n",
       " 'AF4_1.0',\n",
       " 'AF4_1.5',\n",
       " 'AF4_2.0',\n",
       " 'AF4_2.5',\n",
       " 'AF4_3.0',\n",
       " 'AF4_3.5',\n",
       " 'AF4_4.0',\n",
       " 'AF4_4.5',\n",
       " 'AF4_5.0',\n",
       " 'AF4_5.5',\n",
       " 'AF4_6.0',\n",
       " 'AF4_6.5',\n",
       " 'AF4_7.0',\n",
       " 'AF4_7.5',\n",
       " 'AF4_8.0',\n",
       " 'AF4_8.5',\n",
       " 'AF4_9.0',\n",
       " 'AF4_9.5',\n",
       " 'AF4_10.0',\n",
       " 'AF4_10.5',\n",
       " 'AF4_11.0',\n",
       " 'AF4_11.5',\n",
       " 'AF4_12.0',\n",
       " 'AF4_12.5',\n",
       " 'AF4_13.0',\n",
       " 'AF4_13.5',\n",
       " 'AF4_14.0',\n",
       " 'AF4_14.5',\n",
       " 'AF4_15.0',\n",
       " 'AF4_15.5',\n",
       " 'AF4_16.0',\n",
       " 'AF4_16.5',\n",
       " 'AF4_17.0',\n",
       " 'AF4_17.5',\n",
       " 'AF4_18.0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = []\n",
    "freq_range=np.arange(0.5,18.5,0.5)\n",
    "symb='_'\n",
    "#useful_channels_names=['F7','F3','P7','O1','O2','P8','AF4']\n",
    "for index,channel in enumerate(useful_channels_names):\n",
    "    for freq in freq_range:\n",
    "        feature_names.append(channel+symb+str(freq))\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT was then calculated at a time step of 1 s producing a set of time-varying DFT \n",
    "# amplitudes X STFT (t,ω) at 1s intervals within each input EEG channel.\n",
    "t_win = np.arange(0,128)\n",
    "M = 128\n",
    "window_blackman=0.42-0.5*np.cos((2*np.pi*t_win)/(M-1))+0.08*np.cos((4*np.pi*t_win)/(M-1)) #window_blackman = signal.windows.blackmanharris(128)\n",
    "\n",
    "#col is 7\n",
    "power_focus = {}\n",
    "for name in trail_names:\n",
    "    power_focus[name]=np.zeros([col,513,601])\n",
    "    \n",
    "power_unfocus = {}\n",
    "for name in trail_names:\n",
    "    power_unfocus[name]=np.zeros([col,513,601])\n",
    "    \n",
    "power_drowsy = {}\n",
    "for name in trail_names:\n",
    "    power_drowsy[name]=np.zeros([col,513,601])\n",
    "\n",
    "#the output of the stft is 513*601,1 second data will produce 1 column of data,there are 601\n",
    "for name in trail_names:\n",
    "    for i in range(col):\n",
    "        f, t,y1=scipy.signal.stft(data_focus[name][:,i],fs=128, window=window_blackman, nperseg=128, \n",
    "                      noverlap=0, nfft=1024, detrend=False,return_onesided=True, boundary='zeros',\n",
    "                      padded=True)\n",
    "        f, t,y2=scipy.signal.stft(data_unfocus[name][:,i],fs=128, window=window_blackman, nperseg=128, \n",
    "                      noverlap=0, nfft=1024, detrend=False,return_onesided=True, boundary='zeros',\n",
    "                      padded=True)\n",
    "        f, t,y3=scipy.signal.stft(data_drowsy[name][:,i],fs=128, window=window_blackman, nperseg=128, \n",
    "                      noverlap=0, nfft=1024, detrend=False,return_onesided=True, boundary='zeros',\n",
    "                      padded=True)\n",
    "        power_focus[name][i,:,:]=(np.abs(y1))**2\n",
    "        power_unfocus[name][i,:,:]=(np.abs(y2))**2\n",
    "        power_drowsy[name][i,:,:]=(np.abs(y3))**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 513, 601)\n"
     ]
    }
   ],
   "source": [
    "type(power_drowsy['eeg_record3'])\n",
    "print(power_drowsy['eeg_record3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine bins into 0.5HZ, and keep 0-18 HZ.\n",
    "\n",
    "num=[]\n",
    "\n",
    "power_focus_bin = {}\n",
    "for name in trail_names:\n",
    "    power_focus_bin[name]=np.zeros([7,36,601])\n",
    "    \n",
    "power_unfocus_bin = {}\n",
    "for name in trail_names:\n",
    "    power_unfocus_bin[name]=np.zeros([7,36,601])\n",
    "    \n",
    "power_drowsy_bin = {}\n",
    "for name in trail_names:\n",
    "    power_drowsy_bin[name]=np.zeros([7,36,601])\n",
    "\n",
    "for name in trail_names:\n",
    "    for chn in range(col):\n",
    "        j=0\n",
    "        for i in range(1,144,4):\n",
    "            power_focus_bin[name][chn,j,:]=np.average(power_focus[name][chn,i:i+4,:],axis=0)\n",
    "            power_unfocus_bin[name][chn,j,:]=np.average(power_unfocus[name][chn,i:i+4,:],axis=0)\n",
    "            power_drowsy_bin[name][chn,j,:]=np.average(power_drowsy[name][chn,i:i+4,:],axis=0)\n",
    "            #print(np.average(power_drowsy[name][chn,i:i+4,:],axis=0).shape)\n",
    "            #if name=='eeg_record3':\n",
    "            #    if chn==0:\n",
    "            #        num.append((f[i:i+4]))\n",
    "            #    print(j)\n",
    "            j=j+1\n",
    "            \n",
    "#print(num)    \n",
    "#print(len(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 36, 601)\n"
     ]
    }
   ],
   "source": [
    "type(power_drowsy_bin['eeg_record3'])\n",
    "print(power_drowsy_bin['eeg_record3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avarage over 15 seconds running window.\n",
    "\n",
    "power_focus_ave = {}\n",
    "for name in trail_names:\n",
    "    power_focus_ave[name]=np.zeros([7,36,585])\n",
    "    \n",
    "power_unfocus_ave = {}\n",
    "for name in trail_names:\n",
    "    power_unfocus_ave[name]=np.zeros([7,36,585])\n",
    "    \n",
    "power_drowsy_ave = {}\n",
    "for name in trail_names:\n",
    "    power_drowsy_ave[name]=np.zeros([7,36,585])\n",
    "\n",
    "for name in trail_names:\n",
    "    for chn in range(col):\n",
    "        j=0\n",
    "        for k in range(0,585):\n",
    "            power_focus_ave[name][chn,:,j]=np.average(power_focus_bin[name][chn,:,k:k+15],axis=1)\n",
    "            power_unfocus_ave[name][chn,:,j]=np.average(power_unfocus_bin[name][chn,:,k:k+15],axis=1)\n",
    "            power_drowsy_ave[name][chn,:,j]=np.average(power_drowsy_bin[name][chn,:,k:k+15],axis=1)\n",
    "            #print(np.average(power_drowsy_bin[name][chn,:,k:k+15],axis=1).shape)\n",
    "            j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 36, 585)\n"
     ]
    }
   ],
   "source": [
    "type(power_drowsy_ave['eeg_record3'])\n",
    "print(power_drowsy_ave['eeg_record3'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the data into a vector \n",
    "#[252,585]\n",
    "\n",
    "svm_focus = {}\n",
    "for name in trail_names:\n",
    "    svm_focus[name]=np.zeros([252,585])\n",
    "    \n",
    "svm_unfocus = {}\n",
    "for name in trail_names:\n",
    "    svm_unfocus[name]=np.zeros([252,585])\n",
    "    \n",
    "svm_drowsy = {}\n",
    "for name in trail_names:\n",
    "    svm_drowsy[name]=np.zeros([252,585])\n",
    "\n",
    "for name in trail_names:\n",
    "    for j in range(585):      \n",
    "        svm_focus[name][:,j]=power_focus_ave[name][:,:,j].reshape(1,-1)\n",
    "        svm_unfocus[name][:,j]=power_unfocus_ave[name][:,:,j].reshape(1,-1)\n",
    "        svm_drowsy[name][:,j]=power_drowsy_ave[name][:,:,j].reshape(1,-1)\n",
    "    svm_focus[name]=10*np.log(svm_focus[name])\n",
    "    svm_unfocus[name]=10*np.log(svm_unfocus[name])\n",
    "    svm_drowsy[name]=10*np.log(svm_drowsy[name])\n",
    "# now, we get the svm vector 252*585 252 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 585)\n"
     ]
    }
   ],
   "source": [
    "type(svm_focus['eeg_record3'])\n",
    "print(svm_focus['eeg_record3'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA first then SVC, labeling the data into 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "focused -- 2\n",
    "unfocused -- 1\n",
    "drowsy -- 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------0\n",
    "label_focus = [0]*585\n",
    "#--------1\n",
    "label_unfocus = [1]*585\n",
    "#--------2\n",
    "label_drowsy = [2]*585\n",
    "\n",
    "#subject is the variable for all participants\n",
    "\n",
    "subj1_files={'eeg_record3','eeg_record4','eeg_record5','eeg_record6','eeg_record7'}\n",
    "subj2_files={'eeg_record10','eeg_record11','eeg_record12','eeg_record13'}\n",
    "subj3_files={'eeg_record17','eeg_record18','eeg_record19','eeg_record20','eeg_record21'}\n",
    "subj4_files={'eeg_record24','eeg_record25','eeg_record26','eeg_record27'}\n",
    "subj5_files={'eeg_record31','eeg_record32','eeg_record33','eeg_record34'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38.77161708, 38.07711059, 34.24749235, ..., 31.98477085,\n",
       "        30.62809224, 32.66528669],\n",
       "       [40.74957912, 40.30613215, 38.04363382, ..., 30.1867528 ,\n",
       "        28.66557901, 30.5413772 ],\n",
       "       [40.5009797 , 40.18623662, 38.7811119 , ..., 27.3918812 ,\n",
       "        25.79341617, 27.22435716],\n",
       "       ...,\n",
       "       [-4.86491015, -5.45160453, -3.32511895, ..., -1.88315727,\n",
       "        -1.87277832, -1.94374841],\n",
       "       [-6.4999323 , -6.94835025, -4.50868256, ..., -2.97233387,\n",
       "        -3.12943228, -2.60578367],\n",
       "       [-7.86382157, -8.18681765, -5.73174017, ..., -4.79683543,\n",
       "        -4.82842869, -3.92715176]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_focus['eeg_record10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 585)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_focus['eeg_record10'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will try to use the data from all participants to train the model\n",
    "target=[]\n",
    "subj=np.array([]).reshape(252,0).copy()\n",
    "for name in trail_names:\n",
    "    subj=np.concatenate((subj,svm_focus[name]), axis=1)\n",
    "    subj=np.concatenate((subj,svm_unfocus[name]), axis=1)\n",
    "    subj=np.concatenate((subj,svm_drowsy[name]), axis=1)  \n",
    "    target = target+label_focus+label_unfocus+label_drowsy\n",
    "subj=subj.T\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38610, 252)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38610,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the target: 38610\n",
      "the shape of the data from the subject1: (38610, 252)\n"
     ]
    }
   ],
   "source": [
    "print('length of the target:',len(target))\n",
    "print('the shape of the data from the subject1:', subj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part I only train the data for subject1\n",
    "target1=[]\n",
    "subj1=np.array([]).reshape(252,0).copy()\n",
    "for name in subj1_files:\n",
    "    subj1=np.concatenate((subj1,svm_focus[name]), axis=1)\n",
    "    subj1=np.concatenate((subj1,svm_unfocus[name]), axis=1)\n",
    "    subj1=np.concatenate((subj1,svm_drowsy[name]), axis=1)  \n",
    "    target1 = target1+label_focus+label_unfocus+label_drowsy\n",
    "subj1=subj1.T\n",
    "target1 = np.array(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8775, 252)\n",
      "8775\n"
     ]
    }
   ],
   "source": [
    "print(subj1.shape)\n",
    "print(len(target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for subject 2\n",
    "target2=[]\n",
    "subj2=np.array([]).reshape(252,0).copy()\n",
    "for name in subj2_files:\n",
    "    subj2=np.concatenate((subj2,svm_focus[name]), axis=1)\n",
    "    subj2=np.concatenate((subj2,svm_unfocus[name]), axis=1)\n",
    "    subj2=np.concatenate((subj2,svm_drowsy[name]), axis=1)  \n",
    "    target2 = target2+label_focus+label_unfocus+label_drowsy\n",
    "subj2=subj2.T\n",
    "target2 = np.array(target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score for Training data with SVM Model for subject1: 0.9566951566951567\n",
      "Score of For Test data with SVM Model for subject1 : 0.9196581196581196\n"
     ]
    }
   ],
   "source": [
    "# Train the data from subject1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data_train, data_test, data_train_target, data_test_target = train_test_split(subj1, target1, test_size=0.8, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(data_train)\n",
    "X_train_scaled = scaler.transform(data_train)\n",
    "X_test_scaled = scaler.transform(data_test)\n",
    "\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_scaled,data_train_target)\n",
    "print(f'The Score for Training data with SVM Model for subject1:',svc.score(X_train_scaled,data_train_target))\n",
    "print(f'Score of For Test data with SVM Model for subject1 : {svc.score(X_test_scaled,data_test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score for Training data with SVM Model for subject1: 0.9327462660795994\n",
      "Score of For Test data with SVM Model for subject1 : 0.9058349058349059\n"
     ]
    }
   ],
   "source": [
    "# Train the data from subject1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data_train, data_test, data_train_target, data_test_target = train_test_split(subj, target, test_size=0.7, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(data_train)\n",
    "X_train_scaled = scaler.transform(data_train)\n",
    "X_test_scaled = scaler.transform(data_test)\n",
    "\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_scaled,data_train_target)\n",
    "print(f'The Score for Training data with SVM Model for subject1:',svc.score(X_train_scaled,data_train_target))\n",
    "print(f'Score of For Test data with SVM Model for subject1 : {svc.score(X_test_scaled,data_test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335175571825052"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using subject 1 data\n",
    "from sklearn.decomposition import PCA\n",
    "data_train, data_test, data_train_target, data_test_target = train_test_split(subj1, target1, test_size=0.7, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(data_train)\n",
    "X_train_scaled = scaler.transform(data_train)\n",
    "X_test_scaled = scaler.transform(data_test)\n",
    "\n",
    "#PCA should be used on scaled data\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "var = pca.explained_variance_/pca.explained_variance_.sum()\n",
    "var[0:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9324340867988502"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using all data\n",
    "from sklearn.decomposition import PCA\n",
    "data_train, data_test, data_train_target, data_test_target = train_test_split(subj, target, test_size=0.7, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(data_train)\n",
    "X_train_scaled = scaler.transform(data_train)\n",
    "X_test_scaled = scaler.transform(data_test)\n",
    "\n",
    "#PCA should be used on scaled data\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "var = pca.explained_variance_/pca.explained_variance_.sum()\n",
    "var[0:20].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F7_0.5</th>\n",
       "      <th>F7_1.0</th>\n",
       "      <th>F7_1.5</th>\n",
       "      <th>F7_2.0</th>\n",
       "      <th>F7_2.5</th>\n",
       "      <th>F7_3.0</th>\n",
       "      <th>F7_3.5</th>\n",
       "      <th>F7_4.0</th>\n",
       "      <th>F7_4.5</th>\n",
       "      <th>F7_5.0</th>\n",
       "      <th>...</th>\n",
       "      <th>AF4_13.5</th>\n",
       "      <th>AF4_14.0</th>\n",
       "      <th>AF4_14.5</th>\n",
       "      <th>AF4_15.0</th>\n",
       "      <th>AF4_15.5</th>\n",
       "      <th>AF4_16.0</th>\n",
       "      <th>AF4_16.5</th>\n",
       "      <th>AF4_17.0</th>\n",
       "      <th>AF4_17.5</th>\n",
       "      <th>AF4_18.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>0.029122</td>\n",
       "      <td>0.034951</td>\n",
       "      <td>0.040837</td>\n",
       "      <td>0.044614</td>\n",
       "      <td>0.048674</td>\n",
       "      <td>0.052720</td>\n",
       "      <td>0.056133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076070</td>\n",
       "      <td>0.071539</td>\n",
       "      <td>0.065134</td>\n",
       "      <td>0.058620</td>\n",
       "      <td>0.052929</td>\n",
       "      <td>0.047876</td>\n",
       "      <td>0.043528</td>\n",
       "      <td>0.040388</td>\n",
       "      <td>0.039157</td>\n",
       "      <td>0.039701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040783</td>\n",
       "      <td>0.041510</td>\n",
       "      <td>0.041762</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.015346</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026773</td>\n",
       "      <td>-0.010833</td>\n",
       "      <td>0.009681</td>\n",
       "      <td>0.027572</td>\n",
       "      <td>0.037855</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>0.042671</td>\n",
       "      <td>0.041575</td>\n",
       "      <td>0.039375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116226</td>\n",
       "      <td>0.117410</td>\n",
       "      <td>0.118819</td>\n",
       "      <td>0.120041</td>\n",
       "      <td>0.118650</td>\n",
       "      <td>0.110947</td>\n",
       "      <td>0.108734</td>\n",
       "      <td>0.110740</td>\n",
       "      <td>0.113262</td>\n",
       "      <td>0.115509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033493</td>\n",
       "      <td>-0.026927</td>\n",
       "      <td>-0.021924</td>\n",
       "      <td>-0.016793</td>\n",
       "      <td>-0.011050</td>\n",
       "      <td>-0.007083</td>\n",
       "      <td>-0.005920</td>\n",
       "      <td>-0.006001</td>\n",
       "      <td>-0.005659</td>\n",
       "      <td>-0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008082</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>-0.013880</td>\n",
       "      <td>-0.036144</td>\n",
       "      <td>-0.057653</td>\n",
       "      <td>-0.060295</td>\n",
       "      <td>-0.058996</td>\n",
       "      <td>-0.060054</td>\n",
       "      <td>-0.063940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084486</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>0.099009</td>\n",
       "      <td>0.104706</td>\n",
       "      <td>0.112702</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.133634</td>\n",
       "      <td>0.135917</td>\n",
       "      <td>0.135191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.142092</td>\n",
       "      <td>0.144317</td>\n",
       "      <td>0.146752</td>\n",
       "      <td>0.147362</td>\n",
       "      <td>0.141764</td>\n",
       "      <td>0.127473</td>\n",
       "      <td>0.116933</td>\n",
       "      <td>0.106320</td>\n",
       "      <td>0.095004</td>\n",
       "      <td>0.087405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029590</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>-0.013109</td>\n",
       "      <td>-0.024176</td>\n",
       "      <td>-0.029891</td>\n",
       "      <td>-0.031659</td>\n",
       "      <td>-0.033103</td>\n",
       "      <td>-0.035700</td>\n",
       "      <td>-0.038647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.011198</td>\n",
       "      <td>-0.023058</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>-0.006056</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.004458</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>-0.015933</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>-0.012047</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>-0.007277</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>-0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.007942</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>-0.013135</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>-0.003773</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>-0.003808</td>\n",
       "      <td>0.008491</td>\n",
       "      <td>-0.014600</td>\n",
       "      <td>0.020045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031564</td>\n",
       "      <td>-0.018601</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>-0.007217</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>-0.003899</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>-0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.008005</td>\n",
       "      <td>-0.018051</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>-0.006890</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>-0.002985</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>-0.016456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013207</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>-0.006513</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>0.005367</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>-0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.003073</td>\n",
       "      <td>0.007604</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>-0.002205</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>-0.005943</td>\n",
       "      <td>0.010302</td>\n",
       "      <td>-0.015327</td>\n",
       "      <td>0.018337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>-0.005215</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.003657</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>-0.003080</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.001125</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>-0.003512</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.002061</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       F7_0.5    F7_1.0    F7_1.5    F7_2.0    F7_2.5    F7_3.0    F7_3.5  \\\n",
       "1    0.022816  0.023766  0.025675  0.029122  0.034951  0.040837  0.044614   \n",
       "2    0.040783  0.041510  0.041762  0.040228  0.033235  0.021469  0.015346   \n",
       "3    0.116226  0.117410  0.118819  0.120041  0.118650  0.110947  0.108734   \n",
       "4    0.008082  0.005178 -0.001397 -0.013880 -0.036144 -0.057653 -0.060295   \n",
       "5    0.142092  0.144317  0.146752  0.147362  0.141764  0.127473  0.116933   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "248  0.011198 -0.023058  0.016615 -0.006056  0.001499  0.000643 -0.004458   \n",
       "249 -0.007942  0.016551 -0.013135  0.007033 -0.003773  0.002433 -0.003808   \n",
       "250  0.008005 -0.018051  0.014892 -0.006890  0.003564 -0.002985  0.003378   \n",
       "251 -0.003073  0.007604 -0.007018  0.003746 -0.002205  0.003179 -0.005943   \n",
       "252  0.001125 -0.002657  0.001689  0.000148 -0.000626  0.000451 -0.000310   \n",
       "\n",
       "       F7_4.0    F7_4.5    F7_5.0  ...  AF4_13.5  AF4_14.0  AF4_14.5  \\\n",
       "1    0.048674  0.052720  0.056133  ...  0.076070  0.071539  0.065134   \n",
       "2    0.008621  0.000313 -0.007368  ... -0.026773 -0.010833  0.009681   \n",
       "3    0.110740  0.113262  0.115509  ... -0.033493 -0.026927 -0.021924   \n",
       "4   -0.058996 -0.060054 -0.063940  ...  0.084486  0.093112  0.099009   \n",
       "5    0.106320  0.095004  0.087405  ...  0.029590  0.015831  0.000871   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "248  0.009581 -0.015933  0.020045  ...  0.018301 -0.012047  0.008568   \n",
       "249  0.008491 -0.014600  0.020045  ...  0.031564 -0.018601  0.011433   \n",
       "250 -0.006157  0.011490 -0.016456  ... -0.013207  0.009247 -0.006513   \n",
       "251  0.010302 -0.015327  0.018337  ...  0.006584 -0.005215  0.003028   \n",
       "252  0.000094  0.000159 -0.000477  ...  0.004058 -0.003512  0.002737   \n",
       "\n",
       "     AF4_15.0  AF4_15.5  AF4_16.0  AF4_16.5  AF4_17.0  AF4_17.5  AF4_18.0  \n",
       "1    0.058620  0.052929  0.047876  0.043528  0.040388  0.039157  0.039701  \n",
       "2    0.027572  0.037855  0.041952  0.042942  0.042671  0.041575  0.039375  \n",
       "3   -0.016793 -0.011050 -0.007083 -0.005920 -0.006001 -0.005659 -0.004060  \n",
       "4    0.104706  0.112702  0.121357  0.128500  0.133634  0.135917  0.135191  \n",
       "5   -0.013109 -0.024176 -0.029891 -0.031659 -0.033103 -0.035700 -0.038647  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "248 -0.007277  0.007423 -0.007319  0.006262 -0.004365  0.002580 -0.001014  \n",
       "249 -0.007217  0.004953 -0.003899  0.002721 -0.001538  0.001130 -0.000615  \n",
       "250  0.005442 -0.005561  0.005367 -0.003967  0.001596  0.000051 -0.000263  \n",
       "251  0.000422 -0.003657  0.004403 -0.003080  0.001511 -0.000655  0.000165  \n",
       "252 -0.002061  0.001517 -0.000829 -0.000094  0.000875 -0.000918  0.000370  \n",
       "\n",
       "[252 rows x 252 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#sns.heatmap(pca.components_)\n",
    "#print(sum(pca.components_[:,0]**2))\n",
    "\n",
    "pca_map=pd.DataFrame(pca.components_,columns=feature_names,index=np.arange(1,253))\n",
    "#pca.components_.shape\n",
    "pca_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score for Training data with SVM Linear Model for all subjects: 0.7420357420357421\n",
      "Score of For Test data with SVM Linear Model for all subjects : 0.7152107152107152\n"
     ]
    }
   ],
   "source": [
    "#USE SVM linear model\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_scaled,data_train_target)\n",
    "print(f'The Score for Training data with SVM Linear Model for all subjects:',svc.score(X_train_scaled,data_train_target))\n",
    "print(f'Score of For Test data with SVM Linear Model for all subjects : {svc.score(X_test_scaled,data_test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score for Training data with SVM Linear Model for all subjects: 0.9327462660795994\n",
      "Score of For Test data with SVM Linear Model for all subjects : 0.9058349058349059\n"
     ]
    }
   ],
   "source": [
    "#USE SVM linear model\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_scaled,data_train_target)\n",
    "print(f'The Score for Training data with SVM Linear Model for all subjects:',svc.score(X_train_scaled,data_train_target))\n",
    "print(f'Score of For Test data with SVM Linear Model for all subjects : {svc.score(X_test_scaled,data_test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for training with data from 5 participants: 0.9952516619183286\n",
      "the score for test data from 5 participants: 0.9748399748399749\n"
     ]
    }
   ],
   "source": [
    "#Try KNN Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neighbor = KNeighborsClassifier(n_neighbors=3)\n",
    "neighbor.fit(X_train_scaled,data_train_target)\n",
    "print(\"the score for training with data from 5 participants:\",neighbor.score(X_train_scaled,data_train_target))\n",
    "print(\"the score for test data from 5 participants:\",neighbor.score(X_test_scaled,data_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for training with data from 5 participants:0.9148752482085816\n",
      "the score for test data from 5 participants: 0.7855107855107855\n"
     ]
    }
   ],
   "source": [
    "# decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=12)\n",
    "dt.fit(X_train_scaled,data_train_target)\n",
    "print(f\"the score for training with data from 5 participants:{dt.score(X_train_scaled,data_train_target)}\")\n",
    "print(\"the score for test data from 5 participants:\",dt.score(X_test_scaled,data_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for depth in range(1,35):\n",
    "    dt_reg = RandomForestClassifier(max_depth=depth,random_state=0)\n",
    "    dt_reg.fit(X_train_scaled,data_train_target)\n",
    "    train_scores = train_scores +[dt_reg.score(X_train_scaled,data_train_target)]\n",
    "    test_scores = test_scores + [dt_reg.score(X_test_scaled,data_test_target)]\n",
    "    \n",
    "x = list(range(1,35))\n",
    "plt.plot(x,train_scores,c='r',label='train')\n",
    "plt.plot(x,test_scores,c='b',label='test')\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Depth vs. Accuracy for Random Forest Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score for Training data with SVM RBF Model for all subjects: 0.8991625658292325\n",
      "Score of For Test data with SVM RBF Model for all subjects : 0.8756798756798757\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_pca[:,0:30],data_train_target)\n",
    "print(f'The Score for Training data with SVM RBF Model for all subjects:',svc.score(X_train_pca[:,0:30],data_train_target))\n",
    "print(f'Score of For Test data with SVM RBF Model for all subjects : {svc.score(X_test_pca[:,0:30],data_test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score for Training data with SVM RBF Model for all subjects: 0.6604506604506605\n",
      "Score of For Test data with SVM RBF Model for all subjects : 0.6631146631146632\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_pca[:,0:30],data_train_target)\n",
    "print(f'The Score for Training data with SVM RBF Model for all subjects:',svc.score(X_train_pca[:,0:30],data_train_target))\n",
    "print(f'Score of For Test data with SVM RBF Model for all subjects : {svc.score(X_test_pca[:,0:30],data_test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for training with data from 5 participants: 0.991625658292325\n",
      "the score for test data from 5 participants: 0.9633699633699634\n"
     ]
    }
   ],
   "source": [
    "#KNN after PCA\n",
    "neighbor.fit(X_train_pca[:,0:30],data_train_target)\n",
    "print(\"the score for training with data from 5 participants:\",neighbor.score(X_train_pca[:,0:30],data_train_target))\n",
    "print(\"the score for test data from 5 participants:\",neighbor.score(X_test_pca[:,0:30],data_test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for 1 Fold Training: 0.929\n",
      "Score for 1 Fold cv    : 0.901\n",
      "----------------------------------\n",
      "Score for 2 Fold Training: 0.922\n",
      "Score for 2 Fold cv    : 0.909\n",
      "----------------------------------\n",
      "Score for 3 Fold Training: 0.927\n",
      "Score for 3 Fold cv    : 0.899\n",
      "----------------------------------\n",
      "Score for 4 Fold Training: 0.923\n",
      "Score for 4 Fold cv    : 0.905\n",
      "----------------------------------\n",
      "Score for 5 Fold Training: 0.925\n",
      "Score for 5 Fold cv    : 0.905\n",
      "----------------------------------\n",
      "Score of Average For Training: 0.925\n",
      "Score of Average For CV.     : 0.903\n"
     ]
    }
   ],
   "source": [
    "# 5 fold validation\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "data_train_target=data_train_target\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "score_tr=[]\n",
    "score_cv=[]\n",
    "\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "for train,cv in kfold.split(X_train_scaled,data_train_target):\n",
    "    X_tr = X_train_scaled[train]\n",
    "    Y_tr = data_train_target[train]\n",
    "    X_cv = X_train_scaled[cv]\n",
    "    Y_cv = data_train_target[cv]\n",
    "    \n",
    "    tf.random.set_seed(0)\n",
    "    \n",
    "    svm.fit(X_tr,Y_tr)\n",
    "    score_tr.append(svm.score(X_tr,Y_tr))\n",
    "    score_cv.append(svm.score(X_cv,Y_cv))\n",
    "    \n",
    "    print(f'Score for {fold_no} Fold Training: {score_tr[-1]:.3f}')\n",
    "    print(f'Score for {fold_no} Fold cv    : {score_cv[-1]:.3f}')\n",
    "    print('----------------------------------')\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "print(f'Score of Average For Training: {np.mean(score_tr):.3f}')\n",
    "print(f'Score of Average For CV.     : {np.mean(score_cv):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
