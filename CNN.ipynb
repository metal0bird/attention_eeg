{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do not run the below cell again after splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/training\n",
      "images/validation\n",
      "images/training/unfocus\n",
      "images/training/focus\n",
      "images/training/drowsy\n",
      "images/validation/unfocus\n",
      "images/validation/focus\n",
      "images/validation/drowsy\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = 'images'\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "def create_train_val_dirs(root_path):\n",
    " \n",
    "  try:\n",
    "    os.mkdir('images')\n",
    "    os.mkdir('images/validation')\n",
    "    os.mkdir('images/training')\n",
    "    os.mkdir('images/training/focus')\n",
    "    os.mkdir('images/training/unfocus')\n",
    "    os.mkdir('images/training/drowsy')\n",
    "    os.mkdir('images/validation/focus')\n",
    "    os.mkdir('images/validation/unfocus')\n",
    "    os.mkdir('images/validation/drowsy')    \n",
    "  except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "  create_train_val_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")\n",
    "\n",
    "# Test your create_train_val_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
    "\n",
    "  files = []\n",
    "  for filename in os.listdir(SOURCE_DIR):\n",
    "    file = SOURCE_DIR + filename\n",
    "    if os.path.getsize(file)>0:\n",
    "      files.append(filename)\n",
    "    else:\n",
    "      print(filename +\" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files)*SPLIT_SIZE)\n",
    "    testing_length = int(len(files)-training_length)\n",
    "    random_set = random.sample(files,len(files))\n",
    "    training_set = random_set[0:training_length]\n",
    "    testing_set = random_set[training_length:]\n",
    "\n",
    "  for filename in training_set:\n",
    "    curr_file = SOURCE_DIR + filename\n",
    "    target_dir = TRAINING_DIR + filename\n",
    "    copyfile(curr_file,target_dir)\n",
    "\n",
    "  for filename in testing_set:\n",
    "    curr_file = SOURCE_DIR + filename\n",
    "    target_dir = VALIDATION_DIR + filename\n",
    "    copyfile(curr_file,target_dir)\n",
    "  pass\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "FOCUS_SOURCE_DIR = \"dataset/focus/\"\n",
    "UNFOCUS_SOURCE_DIR = \"dataset/unfocus/\"\n",
    "DROWSY_SOURCE_DIR = \"dataset/drowsy/\"\n",
    "\n",
    "TRAINING_DIR = 'images/training/'\n",
    "VALIDATION_DIR = 'images/validation/'\n",
    "\n",
    "TRAINING_FOCUS_DIR = os.path.join(TRAINING_DIR, \"focus/\")\n",
    "VALIDATION_FOCUS_DIR = os.path.join(VALIDATION_DIR, \"focus/\")\n",
    "\n",
    "TRAINING_UNFOCUS_DIR = os.path.join(TRAINING_DIR, \"unfocus/\")\n",
    "VALIDATION_UNFOCUS_DIR = os.path.join(VALIDATION_DIR, \"unfocus/\")\n",
    "\n",
    "TRAINING_DROWSY_DIR = os.path.join(TRAINING_DIR, \"drowsy/\")\n",
    "VALIDATION_DROWSY_DIR = os.path.join(VALIDATION_DIR, \"drowsy/\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_FOCUS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_FOCUS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_UNFOCUS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_UNFOCUS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_DROWSY_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DROWSY_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "if len(os.listdir(VALIDATION_FOCUS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_FOCUS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_UNFOCUS_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_UNFOCUS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(VALIDATION_DROWSY_DIR)) > 0:\n",
    "  for file in os.scandir(VALIDATION_DROWSY_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .8\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(FOCUS_SOURCE_DIR, TRAINING_FOCUS_DIR, VALIDATION_FOCUS_DIR, split_size)\n",
    "split_data(UNFOCUS_SOURCE_DIR, TRAINING_UNFOCUS_DIR, VALIDATION_UNFOCUS_DIR, split_size)\n",
    "split_data(DROWSY_SOURCE_DIR, TRAINING_DROWSY_DIR, VALIDATION_DROWSY_DIR, split_size)\n",
    "# Check that the number of images matches the expected output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original focus's directory has 12870 images\n",
      "Original unfocus's directory has 12870 images\n",
      "Original drowsy's directory has 12870 images\n",
      "\n",
      "There are 10296 images of focus for training\n",
      "There are 10296 images of unfocus for training\n",
      "There are 10296 images of drowsy for training\n",
      "\n",
      "There are 2574 images of focus for validation\n",
      "There are 2574 images of unfocus for validation\n",
      "There are 2574 images of drowsy for validation\n"
     ]
    }
   ],
   "source": [
    "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
    "print(f\"Original focus's directory has {len(os.listdir(FOCUS_SOURCE_DIR))} images\")\n",
    "print(f\"Original unfocus's directory has {len(os.listdir(UNFOCUS_SOURCE_DIR))} images\")\n",
    "print(f\"Original drowsy's directory has {len(os.listdir(DROWSY_SOURCE_DIR))} images\\n\")\n",
    "\n",
    "# Training and validation splits\n",
    "print(f\"There are {len(os.listdir(TRAINING_FOCUS_DIR))} images of focus for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_UNFOCUS_DIR))} images of unfocus for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_DROWSY_DIR))} images of drowsy for training\\n\")\n",
    "\n",
    "print(f\"There are {len(os.listdir(VALIDATION_FOCUS_DIR))} images of focus for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_UNFOCUS_DIR))} images of unfocus for validation\")\n",
    "print(f\"There are {len(os.listdir(VALIDATION_DROWSY_DIR))} images of drowsy for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 598, 598, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 299, 299, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 297, 297, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 148, 148, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 146, 146, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 73, 73, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 71, 71, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 35, 35, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 156800)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 156800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               80282112  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 80543811 (307.25 MB)\n",
      "Trainable params: 80543811 (307.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(600, 600, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 600 x 600 pixels\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Provide the path to your image here\n",
    "image_path = \"dataset/drowsy/eeg_record33_plot567.png\"  # Replace with your actual image path\n",
    "\n",
    "# Read the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was read successfully\n",
    "if image is not None:\n",
    "    # Get the image dimensions (width, height)\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "\n",
    "    # Print the image size\n",
    "    print(\"Image size:\", width, \"x\", height, \"pixels\")\n",
    "else:\n",
    "    print(\"Error: Could not read the image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "#if it doesn't work use loss='sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grader-required-cell\n",
    "\n",
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "\n",
    "  train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=30,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      target_size=(600, 600))\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "  # Pass in the appropriate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=30,\n",
    "                                                                class_mode='categorical',\n",
    "                                                                target_size=(600, 600))\n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30888 images belonging to 3 classes.\n",
      "Found 7722 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
